### Cómo usar el AA: entrenamiento y pérdida 

#### bookmark
Tiempo estimado: 6 minutos
**Entrenar** un modelo simplemente significa aprender (determinar) valores correctos para todas las ponderaciones y las ordenadas al origen de los ejemplos etiquetados. En el aprendizaje supervisado, un algoritmo de aprendizaje automático compila un modelo mediante el análisis de muchos ejemplos y la búsqueda de un modelo que minimice la pérdida. Este proceso se denomina **minimización del riesgo empírico.**

La pérdida es la penalización de una mala predicción. Es decir, la **pérdida** es un número que indica qué tan mala fue la predicción del modelo en un solo ejemplo. Si la predicción del modelo es perfecta, la pérdida es cero; de lo contrario, es mayor. El objetivo de entrenar un modelo es encontrar un conjunto de ponderaciones y ordenadas al origen que, en promedio, tengan una pérdida baja en todos los ejemplos. Por ejemplo, la Figura 3 muestra un modelo con pérdida alta a la izquierda y un modelo con pérdida baja a la derecha. Ten en cuenta lo siguiente sobre la figura:

- #### Las flechas representan la pérdida.
- #### Las líneas azules representan predicciones.

![image](https://github.com/jwattspajaro/Machine_Learning/assets/18930760/2200d7b0-85c1-4cfe-847c-4ad326aa7c46)

#### Figura 3: Pérdida alta en el modelo izquierdo y baja en el modelo derecho.

 

Ten en cuenta que las flechas del trazado izquierdo son mucho más largas que sus contrapartes del trazado derecho. Claramente, la línea en el trazado derecho es un modelo predictivo mucho mejor que la línea en el trazado izquierdo.

Es posible que te preguntes si podrías crear una función matemática (una función de pérdida) que sume las pérdidas individuales de una manera significativa.

**Pérdida al cuadrado: función de pérdida popular**

Los modelos de regresión lineal que se examinan aquí usan una función de pérdida llamada **pérdida al cuadrado** (también conocida como **pérdida L2**). **La pérdida al cuadrado de un solo ejemplo es la siguiente:**

    MSE = \frac{1}{N} \sum_{(x,y)\in D} (y - prediction(x))^2
    
### Donde:

- **(x, y)** es un ejemplo en el que
  -    **x** es el conjunto de atributos (por ejemplo, cantos por minuto, edad y género) que el modelo usa para hacer predicciones.
  -    **Y** es la etiqueta del ejemplo (por ejemplo, temperatura).
- **prediction(x)** es una función de los pesos y los sesgos en combinación con el conjunto de atributos 
.
- **D** es un conjunto de datos que contiene muchos ejemplos etiquetados, que son **(x, y)**  pares.
- **N** es la cantidad de ejemplos en 
.
**Aunque el ECM se usa comúnmente en el aprendizaje automático, no es la única función de pérdida práctica ni la mejor para todas las circunstancias.**

#### Términos clave
- **[Minimización del riesgo empírico](https://developers.google.com/machine-learning/glossary?hl=es-419#ERM)**
- **[Pérdida](https://developers.google.com/machine-learning/glossary?hl=es-419#loss)**
- **[Error cuadrático medio](https://developers.google.com/machine-learning/glossary?hl=es-419#MSE)**
- **[Pérdida al cuadrado](https://developers.google.com/machine-learning/glossary?hl=es-419#squared_loss)***
- **[Capacitación](https://developers.google.com/machine-learning/glossary?hl=es-419#training)**


